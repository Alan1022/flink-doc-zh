

# Project Template for Scala

## Build Tools

Flink projects can be built with different build tools. In order to get quickly started, Flink provides project templates for the following build tools:

*   [SBT](#sbt)
*   [Maven](#maven)

These templates help you to set up the project structure and to create the initial build files.

## SBT

### Create Project

You can scaffold a new project via either of the following two methods:

*   [Use the **sbt template**](#sbt_template)
*   [Run the **quickstart script**](#quickstart-script-sbt)

<figure class="highlight">

```
 $ sbt new tillrohrmann/flink-project.g8 
```

</figure>

This will prompt you for a couple of parameters (project name, flink version...) and then create a Flink project from the [flink-project template](https://github.com/tillrohrmann/flink-project.g8). You need sbt >= 0.13.13 to execute this command. You can follow this [installation guide](http://www.scala-sbt.org/download.html) to obtain it if necessary.

<figure class="highlight">

```
 $ bash <(curl https://flink.apache.org/q/sbt-quickstart.sh) 
```

</figure>

This will create a Flink project in the **specified** project directory.

### Build Project

In order to build your project you simply have to issue the `sbt clean assembly` command. This will create the fat-jar **your-project-name-assembly-0.1-SNAPSHOT.jar** in the directory **target/scala_your-major-scala-version/**.

### Run Project

In order to run your project you have to issue the `sbt run` command.

Per default, this will run your job in the same JVM as `sbt` is running. In order to run your job in a distinct JVM, add the following line to `build.sbt`

<figure class="highlight">

```
fork in run := true
```

</figure>

#### IntelliJ

We recommend using [IntelliJ](https://www.jetbrains.com/idea/) for your Flink job development. In order to get started, you have to import your newly created project into IntelliJ. You can do this via `File -&gt; New -&gt; Project from Existing Sources...` and then choosing your project’s directory. IntelliJ will then automatically detect the `build.sbt` file and set everything up.

In order to run your Flink job, it is recommended to choose the `mainRunner` module as the classpath of your **Run/Debug Configuration**. This will ensure, that all dependencies which are set to _provided_ will be available upon execution. You can configure the **Run/Debug Configurations** via `Run -&gt; Edit Configurations...` and then choose `mainRunner` from the _Use classpath of module_ dropbox.

#### Eclipse

In order to import the newly created project into [Eclipse](https://eclipse.org/), you first have to create Eclipse project files for it. These project files can be created via the [sbteclipse](https://github.com/typesafehub/sbteclipse) plugin. Add the following line to your `PROJECT_DIR/project/plugins.sbt` file:

<figure class="highlight">

```
addSbtPlugin("com.typesafe.sbteclipse" % "sbteclipse-plugin" % "4.0.0")
```

</figure>

In `sbt` use the following command to create the Eclipse project files

<figure class="highlight">

```
> eclipse
```

</figure>

Now you can import the project into Eclipse via `File -&gt; Import... -&gt; Existing Projects into Workspace` and then select the project directory.

## Maven

### Requirements

The only requirements are working **Maven 3.0.4** (or higher) and **Java 8.x** installations.

### Create Project

Use one of the following commands to **create a project**:

*   [Use **Maven archetypes**](#maven-archetype)
*   [Run the **quickstart script**](#quickstart-script)

<figure class="highlight">

```
 $ mvn archetype:generate                               \
      -DarchetypeGroupId=org.apache.flink              \
      -DarchetypeArtifactId=flink-quickstart-scala     \
      -DarchetypeVersion=1.7.1 
```

</figure>

This allows you to **name your newly created project**. It will interactively ask you for the groupId, artifactId, and package name.

<figure class="highlight">

```
 $ curl https://flink.apache.org/q/quickstart-scala.sh | bash -s 1.7.1
```

</figure>

### Inspect Project

There will be a new directory in your working directory. If you’ve used the _curl_ approach, the directory is called `quickstart`. Otherwise, it has the name of your `artifactId`:

<figure class="highlight">

```
$ tree quickstart/
quickstart/
├── pom.xml
└── src
    └── main
        ├── resources
        │   └── log4j.properties
        └── scala
            └── org
                └── myorg
                    └── quickstart
                        ├── BatchJob.scala
                        └── StreamingJob.scala
```

</figure>

The sample project is a **Maven project**, which contains two classes: _StreamingJob_ and _BatchJob_ are the basic skeleton programs for a _DataStream_ and _DataSet_ program. The _main_ method is the entry point of the program, both for in-IDE testing/execution and for proper deployments.

We recommend you **import this project into your IDE**.

IntelliJ IDEA supports Maven out of the box and offers a plugin for Scala development. From our experience, IntelliJ provides the best experience for developing Flink applications.

For Eclipse, you need the following plugins, which you can install from the provided Eclipse Update Sites:

*   _Eclipse 4.x_
    *   [Scala IDE](http://download.scala-ide.org/sdk/lithium/e44/scala211/stable/site)
    *   [m2eclipse-scala](http://alchim31.free.fr/m2e-scala/update-site)
    *   [Build Helper Maven Plugin](https://repo1.maven.org/maven2/.m2e/connectors/m2eclipse-buildhelper/0.15.0/N/0.15.0.201207090124/)
*   _Eclipse 3.8_
    *   [Scala IDE for Scala 2.11](http://download.scala-ide.org/sdk/helium/e38/scala211/stable/site) or [Scala IDE for Scala 2.10](http://download.scala-ide.org/sdk/helium/e38/scala210/stable/site)
    *   [m2eclipse-scala](http://alchim31.free.fr/m2e-scala/update-site)
    *   [Build Helper Maven Plugin](https://repository.sonatype.org/content/repositories/forge-sites/m2e-extras/0.14.0/N/0.14.0.201109282148/)

### Build Project

If you want to **build/package your project**, go to your project directory and run the ‘`mvn clean package`’ command. You will **find a JAR file** that contains your application, plus connectors and libraries that you may have added as dependencies to the application: `target/&lt;artifact-id&gt;-&lt;version&gt;.jar`.

**Note:** If you use a different class than _StreamingJob_ as the application’s main class / entry point, we recommend you change the `mainClass` setting in the `pom.xml` file accordingly. That way, the Flink can run time application from the JAR file without additionally specifying the main class.

## Next Steps

Write your application!

If you are writing a streaming application and you are looking for inspiration what to write, take a look at the [Stream Processing Application Tutorial](//ci.apache.org/projects/flink/flink-docs-release-1.7/tutorials/datastream_api.html#writing-a-flink-program)

If you are writing a batch processing application and you are looking for inspiration what to write, take a look at the [Batch Application Examples](//ci.apache.org/projects/flink/flink-docs-release-1.7/dev/batch/examples.html)

For a complete overview over the APIa, have a look at the [DataStream API](//ci.apache.org/projects/flink/flink-docs-release-1.7/dev/datastream_api.html) and [DataSet API](//ci.apache.org/projects/flink/flink-docs-release-1.7/dev/batch/index.html) sections.

[Here](//ci.apache.org/projects/flink/flink-docs-release-1.7/tutorials/local_setup.html) you can find out how to run an application outside the IDE on a local cluster.

If you have any trouble, ask on our [Mailing List](http://mail-archives.apache.org/mod_mbox/flink-user/). We are happy to provide help.

